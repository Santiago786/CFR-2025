{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 9: Introduction to Pandas and DataFrames\n",
    "\n",
    "## Introduction\n",
    "Pandas is a powerful data manipulation library in Python, providing data structures and functions needed to manipulate structured data seamlessly. In this tutorial, you will learn about Pandas and its core data structure, the DataFrame.\n",
    "\n",
    "## Objectives\n",
    "- Understand the basics of Pandas\n",
    "- Learn how to create and manipulate DataFrames\n",
    "- Perform data analysis with Pandas\n",
    "\n",
    "## Prerequisites\n",
    "- Knowledge of Python: functions, arrays, lists, NumPy, loops, conditionals\n",
    "- Basic understanding of data visualization with Matplotlib\n",
    "\n",
    "## Estimated Time\n",
    "1.5 hours\n",
    "\n",
    "## Part 1: Introduction to Pandas (20 minutes)\n",
    "\n",
    "**What is Pandas?**\n",
    "Pandas is an open-source library providing high-performance, easy-to-use data structures, and data analysis tools for Python. It is particularly useful for data manipulation and analysis.\n",
    "\n",
    "**Installing Pandas (should already be installed)**\n",
    "If you haven't installed Pandas yet, you can do so using pip: pip install pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Importing Pandas**\n",
    "```python\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames**\n",
    "\n",
    "#### Example 1: Creating a DataFrame from an Excel file\n",
    "\n",
    "**Instructions:**\n",
    "1. Create an Excel file with some sample data and save as a .csv file\n",
    "2. Load the file as a DataFrame using `pd.read_csv()`\n",
    "\n",
    "**Specific Instructions:***\n",
    "We have information about the following '90s rappers:\n",
    "\n",
    "- __Tupac__ was born in __Manhattan__ and signed his first record deal at age __20__.  \n",
    "- __The Notorious B.I.G.__ was born in __Brooklyn__ and signed his first deal at age __19__.  \n",
    "- __Snoop Dogg__ was born in __Long Beach__ and signed his first deal at age __19__.  \n",
    "- __Nas__ was born in __Brooklyn__ and signed his first deal at age __18__.  \n",
    "- __Dr. Dre__ was born in __Compton__ and signed his first deal at age __19__.\n",
    "\n",
    "Together, let's create an Excel file with columns \"Name\", \"City\", and \"Age\", and save it as \"rappers.csv\" (File > Save As > File Format: CSV UTF-8).\n",
    "We will upload this file to Jupyter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name        City  Age\n",
      "0                 Tupac   Manhattan   20\n",
      "1  The Notorious B.I.G.    Brooklyn   19\n",
      "2            Snoop Dogg  Long Beach   19\n",
      "3                   Nas    Brooklyn   18\n",
      "4               Dr. Dre     Compton   19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rappers_data = pd.read_csv('rappers.csv')\n",
    "print(rappers_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Problem 1: Create Your Own DataFrame\n",
    "\n",
    "Create a DataFrame for the following data:\n",
    "\n",
    "| Product    | Price | Quantity |\n",
    "|------------|-------|----------|\n",
    "| Laptop     | 1000  | 50       |\n",
    "| Tablet     | 500   | 30       |\n",
    "| Smartphone | 800   | 100      |  \n",
    "\n",
    "Use Excel to enter the data, save it as a CSV file, upload it to Jupyter, then read it with pandas. Name the variable \"df\".\n",
    "\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product  Price  Quantity\n",
      "0      Laptop   1000        50\n",
      "1      Tablet    500        30\n",
      "2  Smartphone    800       100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('prices.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Data Manipulation with Pandas (30 minutes)\n",
    "\n",
    "### Selecting Data\n",
    "\n",
    "#### Example 2: Selecting Columns and Rows\n",
    "\n",
    "Instructions:\n",
    "- Select a single column using `df['column_name']`.\n",
    "- Select multiple columns using `df[['column1', 'column2']]`.\n",
    "- Select rows using `df.iloc[]` for integer-location based indexing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Laptop\n",
      "1        Tablet\n",
      "2    Smartphone\n",
      "Name: Product, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Selecting a single column\n",
    "products = df[\"Product\"]\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product  Price\n",
      "0      Laptop   1000\n",
      "1      Tablet    500\n",
      "2  Smartphone    800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Selecting multiple columns\n",
    "product_price = df[[\"Product\", \"Price\"]]\n",
    "print(product_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product     Laptop\n",
      "Price         1000\n",
      "Quantity        50\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Selecting rows by index\n",
    "first_row = df.iloc[0]\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a subset of rows and columns\n",
    "subset = df.iloc[0:2, 0:3]\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Problem 2: Select Data from Your DataFrame\n",
    "\n",
    "1. Select the **'Product'** and **'Price'** columns from your DataFrame.  \n",
    "2. Next, select the first two rows from your DataFrame.  \n",
    "3. Finally, select the first two rows and two columns.\n",
    "\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Laptop\n",
      "1        Tablet\n",
      "2    Smartphone\n",
      "Name: Product, dtype: object\n",
      "0    1000\n",
      "1     500\n",
      "2     800\n",
      "Name: Price, dtype: int64\n",
      "  Product  Price  Quantity\n",
      "0  Laptop   1000        50\n",
      "1  Tablet    500        30\n",
      "  Product  Price\n",
      "0  Laptop   1000\n",
      "1  Tablet    500\n"
     ]
    }
   ],
   "source": [
    "products = df['Product']  # part 1\n",
    "prices = df[\"Price\"]  # part 1\n",
    "print(products)\n",
    "print(prices)\n",
    "\n",
    "first_two_rows = df.iloc[:2]  # part 2\n",
    "print(first_two_rows)\n",
    "\n",
    "first_two_rows_and_two_columns = df[[\"Product\", \"Price\"]].iloc[:2]  # part 3\n",
    "# OR: first_two_rows_and_two_columns = df.iloc[:2, :2]\n",
    "print(first_two_rows_and_two_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Data\n",
    "\n",
    "**Example 3: Filtering Data Based on Conditions**\n",
    "\n",
    "Instructions:\n",
    "- Filter rows where a column meets a condition using boolean indexing.\n",
    "- Combine multiple conditions using & (and) and | (or).  \n",
    "- **Python evaluates & (and) before | (or).**.  \n",
    "    For example:\n",
    "    <pre markdown>\n",
    "    True or False and True\n",
    "    # evaluates to \"True or (False and True)\"\n",
    "    # which equals \"True or False\"\n",
    "    # which equals True\n",
    "    </pre>\n",
    "- Use parentheses () to override this order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product  Price  Quantity\n",
      "0      Laptop   1000        50\n",
      "2  Smartphone    800       100\n",
      "  Product  Price  Quantity\n",
      "0  Laptop   1000        50\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Price' is greater than 600\n",
    "filtered_data = df[df['Price'] > 600]\n",
    "print(filtered_data)\n",
    "\n",
    "# Combine multiple conditions using & (and) and | (or)\n",
    "filtered_data = df[(df['Price'] > 600) & (df['Quantity'] < 80)]\n",
    "print(filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Problem 3: Filter Data in Your DataFrame\n",
    "\n",
    "(a) Filter rows where the 'Price' is greater than 600 and 'Quantity' is less than 100.  \n",
    "(b) Filter rows where either the 'Price' is less than 600, or 'Quantity is greater than 60.  \n",
    "(c) Filter rows where the 'Price' is greater than 600 and the 'Quantity' is either greater than 80 or less than 60.\n",
    "\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product  Price  Quantity\n",
      "0  Laptop   1000        50\n",
      "\n",
      "      Product  Price  Quantity\n",
      "1      Tablet    500        30\n",
      "2  Smartphone    800       100\n",
      "\n",
      "      Product  Price  Quantity\n",
      "0      Laptop   1000        50\n",
      "2  Smartphone    800       100\n"
     ]
    }
   ],
   "source": [
    "# part a\n",
    "price_gt_600 = df['Price'] > 600  # price > 600 filter\n",
    "qty_lt_100 = df['Quantity'] < 100  # quantity < 100 filter\n",
    "filt1 = df[price_gt_600 & qty_lt_100]  # combine the filters with \"&\"\n",
    "print(filt1)\n",
    "print()  # extra print for spacing\n",
    "\n",
    "# part b\n",
    "price_lt_600 = df['Price']<600  # price < 600 filter\n",
    "qty_gt_60 = df['Quantity']>60  # quantity > 60 filter\n",
    "filt2 = df[price_lt_600 | qty_gt_60]  # combine the filters with \"|\"\n",
    "print(filt2)\n",
    "print()  # extra print for spacing\n",
    "\n",
    "# part c - this is complicated, so break it up!\n",
    "price_filter = df['Price']>600  # filter for price\n",
    "\n",
    "quantity_greater_than_80 = df['Quantity']>80  # filter for quantity greater than 80\n",
    "quantity_less_than_60 = df['Quantity']<60  # filter for quantity less than 60\n",
    "quantity_filter = quantity_greater_than_80 | quantity_less_than_60  # filter for quantity > 80 or <60\n",
    "\n",
    "# combine filters\n",
    "filt3 = df[price_filter & quantity_filter]  # combine the price and quantity filters\n",
    "print(filt3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding and Removing Data\n",
    "\n",
    "#### Example 4: Adding and Removing Columns\n",
    "\n",
    "Instructions:\n",
    "Add a new column to the DataFrame.\n",
    "Remove a column using df.drop().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "df['Discount'] = [0.1, 0.2, 0.15]\n",
    "\n",
    "# Removing a column\n",
    "df.drop('Discount', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Problem 4: Add and Remove Columns in Your DataFrame\n",
    "\n",
    "Add a 'Discount' column to your DataFrame with values [10, 15, 20]. Then, remove the 'Quantity' column.  \n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product  Price  Quantity\n",
      "0      Laptop   1000        50\n",
      "1      Tablet    500        30\n",
      "2  Smartphone    800       100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('prices.csv')  # ead the original data\n",
    "\n",
    "# add a discount column\n",
    "df['Discount'] = [10,15,20]\n",
    "\n",
    "# remove Quantity. Axis=1 means drop a column. inplace=True tells python to change our dataframe.\n",
    "df.drop('Discount', axis=1, inplace=True)\n",
    "# df = df.drop(\"Discount\", axis=1)  # equivalent to inplace=True\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Interested Students: Advanced DataFrame Operations\n",
    "\n",
    "**Handling Missing Data**\n",
    "\n",
    "#### Example 5: Identifying and Handling Missing Data*\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Identify missing data using `df.isnull()`.\n",
    "- Drop rows with missing data using `df.dropna()`.\n",
    "- Fill missing data using `df.fillna()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load the rappers data for this example\n",
    "df = pd.read_csv('rappers.csv')\n",
    "\n",
    "# Adding missing data\n",
    "df.loc[2, 'Age'] = np.nan\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying missing data\n",
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with missing data\n",
    "df_dropped = df.dropna()\n",
    "print(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing data\n",
    "df_filled = df.fillna(0)\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Problem 5: Handle Missing Data in Your DataFrame\n",
    "\n",
    "(a) Set the price of the first item to missing (np.nan).  \n",
    "(b) Then create a copy of your dataframe, but drop all rows with missing data.  \n",
    "(c) Finally, create a copy of your dataframe, but fill all missing data with 0.  \n",
    "\n",
    "Note: to set the price of the _n_-th item, use: df.loc[_n_, 'Price'] = ...\n",
    "\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and Aggregating Data\n",
    "\n",
    "**Example 6: Grouping and Aggregating Data**\n",
    "\n",
    "**Instructions:**\n",
    "- Group data using `df.groupby()`.\n",
    "- Perform aggregation functions such as `sum()`, `mean()`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('rappers.csv')\n",
    "\n",
    "# Group and aggregate\n",
    "grouped = df.groupby('Artist')['NetWorth']\n",
    "sum_networth = grouped.sum()\n",
    "mean_networth = grouped.mean()\n",
    "\n",
    "print(\"Sum of all Estimates by Artist:\")\n",
    "print(sum_networth)\n",
    "print(\"\\nAverage Net Worth Estimate by Artist:\")\n",
    "print(mean_networth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Problem 6: Group and Aggregate Data in Your DataFrame\n",
    "\n",
    "You now have the following data:  \n",
    "| Product    | Price | Quantity |\n",
    "|------------|-------|----------|\n",
    "| Laptop     | 1000  | 50       |\n",
    "| Tablet     | 500   | 30       |\n",
    "| Smartphone | 800   | 100      |\n",
    "| Laptop     | 1200  | 70       |\n",
    "| Tablet     | 450   | 20       |\n",
    "\n",
    "Create a dataframe from the above data, group by 'Product' and calculate the total and average price for each product.\n",
    "\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and Joining DataFrames\n",
    "\n",
    "#### Example 8: Merging DataFrames\n",
    "\n",
    "Instructions:  \n",
    "- Create dataframes from Table 1 and Table 2, named \"table1.csv\" and \"table2.csv\", respectively.  \n",
    "- Merge two DataFrames using pd.merge().\n",
    "- Perform different types of merges: inner, outer, left, right.  \n",
    "\n",
    "    - _inner_: keep **only rows whose ID appears in both tables**.\n",
    "    - _outer_: keep **every row** from both tables, **filling gaps with NaN.**\n",
    "    - _left_: keep **all rows from the first table** and **only matching rows from the second**.  \n",
    "    - right: keep **all rows from the second table** and **only matching rows from the first**.  \n",
    "      \n",
    "Table 1:  \n",
    "| ID | Artist     | Record Label             |\n",
    "|----|------------|--------------------------|\n",
    "| 1  | Tupac      | Interscope               |\n",
    "| 2  | Biggie     | Bad Boy Records          |\n",
    "| 3  | Snoop Dogg | Doggystyle Records       |\n",
    "| 4  | Dr. Dre    | Aftermath Entertainment  |  \n",
    "\n",
    "Table 2:  \n",
    "| ID | Age |\n",
    "|----|-----|\n",
    "| 3  | 23  |\n",
    "| 4  | 31  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"table1.csv\")\n",
    "df2 = pd.read_csv(\"table2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join\n",
    "merged_df_inner = pd.merge(df1, df2, on=\"ID\", how=\"inner\")\n",
    "print(merged_df_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join\n",
    "merged_df_outer = pd.merge(df1, df2, on=\"ID\", how=\"outer\")\n",
    "print(merged_df_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join\n",
    "merged_df_left = pd.merge(df1, df2, on=\"ID\", how=\"left\")\n",
    "print(merged_df_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right join\n",
    "merged_df_right = pd.merge(df1, df2, on=\"ID\", how=\"right\")\n",
    "print(merged_df_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Problem 8: Merge DataFrames\n",
    "\n",
    "Create two DataFrames with some common columns and merge them using an inner join.\n",
    "\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a data file\n",
    "\n",
    "#### Example 9: Load a CSV file\n",
    "\n",
    "Instructions:\n",
    "- use pd.read_CSV(file_name) to convert the Berkeley Earth data to pandas\n",
    "- you can now use everything we learned above to analyze it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example CSV\n",
    "file_name = 'GAST_BerkeleyEarth_1850-2023.csv'\n",
    "berkeley_earth_df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Problem 9: Analyze a data file\n",
    "\n",
    "(a) Read the Berkeley Earth data from above, group by the 'Year' column, and compute the average temperature per year (temperature is in the 'Monthly Average' column).\n",
    "(b) Make a plot of average temperature versus year.  \n",
    "\n",
    "Hint 1: group by 'Year', select the 'Monthly Average' column, take the mean, then use the .reset_index() method.  \n",
    "Example: <pre markdown> grouped = df.groupby(COL_X)[COL_Y].mean().reset_index() </pre>\n",
    "  \n",
    "Hint 2: You can loop through the rows of a dataframe using the following syntax:  \n",
    "<pre markdown>\n",
    "for index, row in df.iterrows():\n",
    "    year = index\n",
    "    avg_temp = row['Monthly Average']\n",
    "    …\n",
    "</pre>\n",
    "\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you have learned how to:\n",
    "- Create and manipulate DataFrames using Pandas\n",
    "- Select, filter, add, and remove data\n",
    "- Handle missing data\n",
    "- Group and aggregate data\n",
    "- Merge and join DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
